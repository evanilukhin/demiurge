[
  {
    "header": "Rails API + SPA authorization — Authorization by JWT",
    "head_image": null,
    "summary": "One of the ways to provide authorization is to use JSON Web Tokens or JWT. It is a popular way to imp...",
    "main_part": "One of the ways to provide authorization is to use JSON Web Tokens or JWT. It is a popular way to implement authorization between different services by logging in only once. In this blog post, I’ll briefly explain what is it, tell about some pitfalls and show how to add in an application.\n\n# What is it, and why is it so popular?\n\n\nBriefly, it’s a signed string that contains some information in a not ciphered form and a verification signature, that proves that information was not changed. JWTs **doesn’t protect data from stealing**. They are only **protected from changing**. The closest analogy from the real world is an RFID ID card with the printed on it information. Everyone can see what is written on a card, but only who know secret can change it. Furthermore, someone can steal your card and freely use one. I will not explain in detail about the structure of JWTs, it very clear and short described on the official site.\n\n## And why is this approach so popular today?\n\nMost of the modern applications consist of a bunch of microservices developing by different teams. First returns frontend, second provides an API, third gathers statistics of usage, etc., and they communicate with each other. We want to know some information about a request (who made it, user type and etc.) and that this information has not tampered.\n\nThere are listed the most popular cases of usage JWTs:\n\n- authorization between independent SPA and API;\n- providing authorization for different web-applications using only one for an authentification;\n- secured information exchange between services, tokens guarantees that information was not changed during transmission.\n\nJWT is a good solution for authorization but not without some controversies. \n\nLet’s go to nuances of usage and caveats.\n\n### Confidential information exchange\n\nThis mentioned in almost all posts about JWTs, and I will remind too.\n\n**DO NOT USE JSON WEB TOKENS FOR STORING AND PASSING CONFIDENTIAL DATA!** \nLike passwords, information from official documents and etc. Everyone who has a token sees the content.\n\n### Stateless requests\n\nIn many articles are spoked of the next advantage of JWTs— stateless. It means that we store all necessary information inside the token, though we can reduce the amount of connection to a central database. It makes sense in the environment with dozens of microservices. But, what if a token was compromised. Yes usually it has an expiration date, but what if we must cancel it right now.\n\nThere is a simple solution, unfortunately, it violates the mentioned above advantage. We can store blacklisted tokens in a database (Redis for example) to deny access by using an invalid token. Another good idea is to save user sessions(user id + valid token + token expiration date). It will be a little bit slow, but we can always get the information about how much users are logged in. Furthermore, the application must go to a database every time processing a request, as a consequence recommended to use for a blacklist/session storage an in-memory database with O(1) access time.\n\nIn many cases, it is not necessary, however, keep it in mind when you decide to use JWTs for users authentication/authorization.\n\n## Time to practice\n\nFor this service, I used the most popular authentification solution for the Ruby on Rails — [Knock](https://github.com/nsarno/knock). This gem leverages efforts for creating and decoding tokens. Let’s look at how it easy.\n\n- add gem to the project [link](https://github.com/nsarno/knock#installation);\n- add finding user by the login to the User model(by default Knock uses email field);\n\n```ruby\ndef self.from_token_request(request)\n  # Returns a valid user, `nil` or raise `Knock.not_found_exception_class_name`\n  login = request.params['auth'] \u0026\u0026 request.params['auth']['login']\n  user = find_by(login: login)\n  if user.present?\n    return user\n  else\n    raise Knock.not_found_exception_class_name\n  end\nend\n```\n\nCreate UserTokenController to generate token and UsersController, that returns user’s name, when token is correct and user still exists\n\n```ruby\nmodule Api\n  module Jwt\n    class UsersController \u003c ApplicationController\n      include Knock::Authenticable\n\n      before_action :authenticate_user\n\n      def name\n        render json: {name: current_user.name}\n      end\n    end\n  end\nend\n```\n\nand controller, that generates tokens for the User.\n\n```ruby\nmodule Api\n  module Jwt\n    class UserTokenController \u003c Knock::AuthTokenController\n      skip_before_action :verify_authenticity_token\n    end\n  end\nend\n```\n\nPretty simple!\n\nOn this scheme is depicted how it works.\n\n![](https://habrastorage.org/webt/fu/nb/nn/funbnn0l-z0tglywc9yyugwc8am.png)\n\nWe make POST request with the form-data(login and password in our case) and get token in response. This token can be attached as [the bearer authentification token](https://tools.ietf.org/html/rfc6750) in headers, or just transferred in a request body.\n\nYes, it looks like a simple and working solution, but what can happen if you decide to use it in a web application(SPA, for example) that works from a browser. A gotten token can be stored by javascript to next usage in headers to local storage or normal cookies(not HTTP only), it means that anyone(third-party javascript libraries, browser extensions, etc.) has access to this token. What is wrong with it? Correct! The token is vulnerable to [XSS attacks](https://www.owasp.org/index.php/Cross-site_Scripting_(XSS)).\n\nBut there is a way to avoid it — cookies with [HttpOnly flag](https://www.owasp.org/index.php/HttpOnly). In Rails you can use or sessions (special encrypted cookies, httponly by default) or just cookie with this flag. The main difference between them is next. A session cookie is encrypted by default, a usual cookie you must encrypt manually. I’ll show how to realize it on sessions.\n\n### JWT inside session\n\nBy default sessions are destroyed right after closing a browser, though if you want to increase their expiration date add this parameter to the session initializer config/initializers/session_store.rb:\n\n```ruby\nRails.application.config.session_store(:cookie_store, expire_after: 7.days)\n```\n\nor to the middleware in config/application.rb when you use api-only application:\n\n```ruby\nconfig.middleware.use ActionDispatch::Session::CookieStore, expire_after: 7.days\n```\n\nIn case, when you want to store and configure it separately from session use encrypted, httponly cookie.\n\nNext, you should redefine current knock behaviour for creating token:\n\n```ruby\nclass UserTokenController \u003c Knock::AuthTokenController\n  include ::ActionController::Cookies\n  skip_before_action :verify_authenticity_token\n\n  def create\n    session[:jwt] = auth_token.to_json\n    render body: nil, status: :created\n  end\nend\n```\n\nAs you can see, I skipped [CSRF verification](https://api.rubyonrails.org/classes/ActionController/RequestForgeryProtection.html), because this API works with SPA with another origin and Knock::AuthToken depends from AuthController::Base, where it enabled by default. In the redefined method create I add token to the session and render nothing with the status code 201.\n\nUsersController will be a little bit more complicated:\n\n```ruby\nclass UsersController \u003c ApplicationController\n  include ::ActionController::Cookies\n  before_action :find_user\n\n  def name\n    if @current_user\u0026.is_a?(User)\n      render json: { name: @current_user.name }\n    else\n      render json: { message: 'Bad user' }, status: 401\n    end\n  end\n\n  private\n\n  def find_user\n    jwt = session[:jwt]\n    if jwt.present?\n      token = JSON.parse(jwt)['jwt']\n      user_id = Knock::AuthToken.new(token: token).payload['sub']\n      @current_user = User.find_by(id: user_id)\n    else\n      render json: { message: 'Token not found' }, status: 401\n    end\n  end\nend\n```\n\nIn find_user I try to find the token in the session and decipher it. How it looks on scheme:\n\n![](https://habrastorage.org/webt/fa/hq/6j/fahq6jfy02j01o0mgyg8dfg9khs.png)\n\nThat’s all. We saw how to authenticate a user by using JWT itself and with combination with cookies using Knock.\n\n___\n\nP.S. Some useful articles that helped me to understand this topic\n\n- Flavio Copes - [JWT authentication: When and how to use it](https://blog.logrocket.com/jwt-authentication-best-practices/)\n- Jan Brennenstuhl— [Stateless JWT authentification](https://www.jbspeakr.cc/purpose-jwt-stateless-authentication/)\n- Sophie DeBenedetto — [Great short article about adding JWT to Rails](https://www.thegreatcodeadventure.com/jwt-storage-in-rails-the-right-way/)",
    "tags": ["rails", "jwt", "authorization"]
  },
  {
    "header": "Guide to install PyTorch with CUDA on Ubuntu 18.04",
    "head_image": "https://thepracticaldev.s3.amazonaws.com/i/v695f3x3cdf1pplatwko.jpg",
    "summary": "Guide to install PyTorch with CUDA on Ubuntu 18.04     Yesterday I was installing PyTorch an...",
    "main_part": "# Guide to install PyTorch with CUDA on Ubuntu 18.04\n\n![Alt Text](https://thepracticaldev.s3.amazonaws.com/i/ukv2ncfhz9jwrcmla6at.png)\n\nYesterday I was installing PyTorch and encountered with different difficulties during the installation process. Let me share the resulting path, that brought me to the successful installation. I hope this little instruction will save you time and show further direction. \n\n### Install Python3.8\nPyTorch requires Python version 3.7 or above, so I decided to install the latest stable version on this moment Python 3.8. Standard Ubuntu repository has maximum 3.6, so I added repository from the “deadsnakes” team [link](https://launchpad.net/~deadsnakes/+archive/ubuntu/ppa). \n```bash\nsudo add-apt-repository ppa:deadsnakes/ppa\nsudo apt-get update\nsudo apt install python3.8 python3.8-dev python3.8-venv\n```\n- `python3.8-dev` - requires for building C extensions\n- `python3.8-venv` - provides support for creating lightweight “virtual environments” with their own site directories\n\n### Install CUDA\nMy graphic card supports CUDA, so why not take advantage of this.\nJust choose one of the type of installation [there](https://developer.nvidia.com/cuda-downloads?target_os=Linux\u0026target_arch=x86_64\u0026target_distro=Ubuntu\u0026target_version=1804). I selected `deb(network)`:\n\n```bash\nwget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-ubuntu1804.pinsudo \nmv cuda-ubuntu1804.pin /etc/apt/preferences.d/cuda-repository-pin-600\nsudo apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/7fa2af80.pub\nsudo add-apt-repository \"deb http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/ /\"\nsudo apt-get update\nsudo apt-get -y install cuda\n```\n### Install pip\n\nBefore pip installation, you should create a new [virtual environment](https://packaging.python.org/tutorials/installing-packages/#creating-virtual-environments) for Python. On the first step, we installed `python3.8-venv` exactly for this purpose. \n\n```bash\npython3.8 -m venv ~/python_env/my_env\n```\n\nThis command creates a new local environment in your local folder. After the directory has been created \"activate\" this environment by the next command. (Works only for bash/zsh, for other shells look [there](https://docs.python.org/3/library/venv.html))\n\n```bash\nsource ~/python_env/my_env/bin/activate\n```\n\nThen install `pip` following by the (instruction)[https://pip.pypa.io/en/stable/installing/]\n\n```bash\ncurl https://bootstrap.pypa.io/get-pip.py -o get-pip.py\npython get-pip.py\n```\n\nPerfect! Let's go to the finish. 🏁\n\n### And the final step - Get, compile and install PyTorch\n\nFirstly install `cmake` and clone the necessary version of the PyTorch. Don't be afraid, repository really big, so it takes a lot of time:\n```bash\nsudo apt install cmake\ngit clone --recursive https://github.com/pytorch/pytorch.git\ngit submodule sync\ngit submodule update --init --recursive\n```\n\nThan install all required Python packages using pip:\n\n\u003e Ensure that you use right Python virtual environment \n\n```bash\npython3.8 -m pip install numpy ninja pyyaml mkl mkl-include setuptools cmake cffi typing\n```\n\nEnsure that you are in the cloned directory and run the next commands:\n```bash\nexport CMAKE_PREFIX_PATH=${CONDA_PREFIX:-\"$(dirname $(which conda))/../\"}\npython setup.py install\n```\n\n:tada: Congratulations, you are installed the PyTorch in your local virtual environment. Time to check it!\n\n### Running\n\nCreate the file `torch_program.py` and add the next lines:\n```python\nfrom __future__ import print_function\nimport torch\n\nx = torch.ones(5, 5)\n\nprint(x)\n\nif torch.cuda.is_available():\n    device = torch.device(\"cuda\") # a CUDA device object\n    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n    x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n    z = x + y\n    print(z)\n    print(z.to(\"cpu\", torch.double))\n```\n\nIf all installed correctly there will be the followed resuls:\n```\ntensor([[1., 1., 1., 1., 1.],\n        [1., 1., 1., 1., 1.],\n        [1., 1., 1., 1., 1.],\n        [1., 1., 1., 1., 1.],\n        [1., 1., 1., 1., 1.]])\ntensor([[2., 2., 2., 2., 2.],\n        [2., 2., 2., 2., 2.],\n        [2., 2., 2., 2., 2.],\n        [2., 2., 2., 2., 2.],\n        [2., 2., 2., 2., 2.]], device='cuda:0')\ntensor([[2., 2., 2., 2., 2.],\n        [2., 2., 2., 2., 2.],\n        [2., 2., 2., 2., 2.],\n        [2., 2., 2., 2., 2.],\n        [2., 2., 2., 2., 2.]], dtype=torch.float64)\n```\n\nIf you get stuck following this manual feel free to write in comments about it, I'll be sure to expand this post with the new information.\n\nHappy Machine Learning! 🤖📖\n\n",
    "tags": ["python", "beginners", "pytorch", "ubuntu"]
  },
  {
    "header": "Ruby Interview Tasks - Simple word calculator",
    "head_image": null,
    "summary": "Recently during an interview live coding session, I got a pretty interesting task:   # Make this code...",
    "main_part": "Recently during an interview live coding session, I got a pretty interesting task:\n```ruby\n# Make this code working\none.plus.two.equal # =\u003e\u003e 3\none.minus.three.equal # =\u003e -2\n```\n\nI was tired and tried to solve it by adding some method to a String instance methods like there:\n\n```ruby\none = '1'\n\ndef one.plus\n  temp_plus = \"#{self}+\"\n\n  def temp_plus.two\n    temp_plus_two = \"#{self}2\"\n\n    def temp_plus_two.equal\n      eval(self)\n    end\n\n    temp_plus_two\n  end\n\n  temp_plus\nend\n\ndef one.minus\n  temp_minus = \"#{self}-\"\n\n  def temp_minus.three\n    temp_minus_three = \"#{self}3\"\n\n    def temp_minus_three.equal\n      eval(self)\n    end\n\n    temp_minus_three\n  end\n\n  temp_minus\nend\n\n# Yes, it works\npp one.plus.two.equal # =\u003e 3\npp one.minus.three.equal =\u003e -2\n```\n\nLooks bulky and terrible. Yes, Ruby allows to do this, but it is natural monkey patching, and I would not be used similar construction in real projects.\nSix hours later, when I woke up, I realized that there is exist a significantly more straightforward and elegant solution. It’s just a realization of the method chaining pattern:\n\n```ruby\nclass Evaluator\n  class \u003c\u003c self\n    def operation(name, expression_part)\n      define_method(name) do\n        return_new_instance expression_part\n      end\n    end\n  end\n  \n  operation :plus,  '+'\n  operation :minus, '-'\n  operation :two,   '2'\n  operation :three, '3'\n\n  def initialize(expression = '')\n    @expression = expression\n  end\n\n  def equal\n    eval(@expression)\n  end\n\n  private\n\n  def return_new_instance(expression_part)\n    @expression = \"#{@expression}#{expression_part}\"\n    self.class.new(@expression)\n  end\nend\n\none = Evaluator.new('1')\npp one.plus.two.equal # =\u003e 3\npp one.minus.three.equal # =\u003e -2\n```\n\nPretty neat!\nThis task is well for estimating the level of a developer. Specifically, the knowledge of method chaining pattern(interviewee mentioned it or just used it), how to use metaprogramming and awareness about monkey patching and bad solutions.",
    "tags": ["ruby"]
  },
  {
    "header": "Rails API + React SPA authentication problem — Authentication by cookies",
    "head_image": null,
    "summary": "Introduction   In this series of articles, I’ll cover different ways for a user authentifica...",
    "main_part": "## Introduction\n\nIn this series of articles, I’ll cover different ways for a user authentification in systems with separated frontend and backend. As an example, I took my lovely programming language Ruby with RoR, with which I’ve been working already four years, for API and React application, based on CRA template, for separated frontend.\n\nSource code for SPA you can find [here](https://github.com/evanilukhin/auth_playground_react_spa). For API — [here](https://github.com/evanilukhin/auth_playground_rails_api).\n\n### Problem\n\nImagine that some people request to develop a system for storing the most valuable thing for them — their names. Besides, users love to admire their treasure only personally. For it, they wish that the system must show name only after logging in and must not ask it for one week. Moreover, they are planning to develop GUI and API by different teams, so these parts must be independent applications.\n\n\u003cimg src=\"https://github.com/evanilukhin/articles/blob/master/posts/Rails%20API%20+%20React%20SPA%20authentication/High%20level%20view.jpg?raw=true\"\u003e\n\n### Design — API\n\nA core entity of the API has a model User that contains only three fields:\n* **login** — string which users do not scare to show;\n* **password** — stored as a password digest;\n* **name** — sacred for every user information that we only show when they are authorized.\n\n### Design — SPA\n\nThe page has only one block, that is show login form if user not authorized and not blank field “Name” above in case of successful authentication.\n\nLet’s go further and consider how to authenticate our users by cookies.\n\n## Authentication by cookies\n\nThe most common and obvious approach is to use HTTP cookies for storing auth information. Ruby on Rails has two similar mechanisms for working with cookies, it’s cookies themselves and sessions. For cookies, we can set an httponly flag, that protects from xss attacks, domain, and expiration date. Sessions are stored in cookies inside an encrypted string, where an httponly flag is set by default. For this example, I took sessions because the SPA does not read from cookies.\n\n### How it works:\n\n* SPA sends a POST request with login and password\n* API write user.id in the session cookie\n* Component try to get the name of the user sending a request with the session\n* API find a user by user id and if all right return name of this user\n* Component is updated\n\u003cdiv style=\"text-align:center\"\u003e\n\u003cimg src=\"https://github.com/evanilukhin/articles/blob/master/posts/Rails%20API%20+%20React%20SPA%20authentication/cookies_sequence_1.jpg?raw=true\"\u003e\n\u003c/div\u003e\n\nLet’s dive deeper.\n\nUsually, SPA and API are deployed on different hosts, hence there appears the next problem — how to pass and modify cookies. By default browser does not set cookies from another origin by javascript. But we can easily enable it.\n\n### SPA side.\n\nFor communicating with a server SPA uses the Fetch API that is provided in a global window scope. For enabling a possibility to send and receive cookies from resources with a different origin. We must set the next option:\n\n* credentials: ‘include’ — it enables sending cookies for cross-origin requests by default it is set for the same origin;\n* mode: ‘cors’ — allows to work with all headers related to CORS. By default, it allows only for same-origin requests.\n\nExamples you will find further.\n\n## Server side.\n\nTo enable the supporting of cross-origin requests in RoR, you must add gem rack-cors that provides support for CORS for a Rack middleware. When you create rails application from a generator with API you need only uncomment string *“gem ‘rack-cors’”* in Gemfile and content of the config file `config/initializers/cors.rb`. For setting cookies you must set parameter credentials as true. Important notice, it works only if the origin is not a wildcard. For security reason and flexibility I usually set it from environment variables like there:\n\n```ruby\nRails.application.config.middleware.insert_before 0, Rack::Cors do\n  allow do\n    origins ENV['SPA_ORIGIN']\n\n    resource '*',\n      headers: :any,\n      methods: [:get, :post, :put, :patch, :delete, :options, :head],\n      credentials: true\n  end\nend\n```\n\n### Sending and handling requests\n\nAfter the setting our projects for work with cookies let’s look at how are requests handled.\n\nPost request contains data and cors friendly settings, about I mentioned above.\n\n```jsx\n\n    const authUrl = apiUrl + 'login'\n    let payload = {\n      'data': {\n        'login': this.state.login,\n        'password': this.state.password\n      }\n    }\n\n    let headers = {\n      'Content-Type': 'application/json'\n    };\n\n    fetch(authUrl, {\n      method: 'POST',\n      mode: 'cors',\n      cache: 'no-cache',\n      headers: headers,\n      redirect: 'follow',\n      referrer: 'no-referrer',\n      body: JSON.stringify(payload),\n      credentials: 'include'\n    });\n```\n\nRequest handled by standard Rails controller. API finds a user and if all right writes user’s id in a session.\n\n```ruby\nclass AuthController \u003c ApplicationController\n  include ::ActionController::Cookies\n\n  def login\n    if params['data']['login'] \u0026\u0026 params['data']['password']\n      user = User.find_by(login: params['data']['login'])\n      if user \u0026\u0026 user.authenticate(params['data']['password'])\n        session[:user_id] = user.id\n      else\n        render json: {message: 'Wrong login or password'}, status: 403\n      end\n    else\n      render json: {}, status: 401\n    end\n  end\nend\n```\n\nNext requests for getting the name send this session and controller just read it and sends name.\n\n```jsx\nlet username_url = apiUrl + \"name\";\n\nlet headers = new Headers({\n  'Content-Type': 'application/json'\n});\n\nif(this.state.name === null) {\n  fetch(username_url, {\n    method: 'GET',\n    mode: 'cors',\n    headers: headers,\n    cache: 'no-cache',\n    redirect: 'follow',\n    referrer: 'no-referrer',\n    credentials: 'include'\n  })\n  .then(function (response) {\n    return response.json();\n  })\n  .then(myJson =\u003e {\n    this.setState({name: myJson['name']});\n  });\n};\n```\n\n..and related controller:\n```ruby\nclass UsersController \u003c ApplicationController\n      include ::ActionController::Cookies\n      before_action :find_user\n\n      def name\n        if @current_user.present? \u0026\u0026 @current_user.is_a?(User)\n          render json: {name: @current_user.name}\n        else\n          render json: {message: 'Bad user'}, status: 401\n        end\n      end\n\n      private\n\n      def find_user\n        user_id = session[:user_id]\n        @current_user = User.find_by(id: user_id)\n      end\nend\n```\n\nPretty simple!\n\n### Pros\n\nSecurity — httponly flag prevents cookies from stealing your auth data by XSS attacks. (I hope that you use https by default).\n\nSimplicity — mechanisms for working with cookies and sessions are proven and exist almost in all frameworks.\n\n### Cons\n\nWorks only inside with web-browsers.",
    "tags": ["rails", "react", "architecture"]
  },
  {
    "header": "CircleCI + AWS How to create CI/CD pipeline from scratch Part 0 - Preparation",
    "head_image": "https://res.cloudinary.com/practicaldev/image/fetch/s--STRtjcyT--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://dev-to-uploads.s3.amazonaws.com/i/zqc3kn47x4qg2tg5mm9c.png",
    "summary": "Introduction   In this series of posts, I'm going to show how to set up the CI/CD environmen...",
    "main_part": "## Introduction\n\nIn this series of posts, I'm going to show how to set up the CI/CD environment using AWS and CircleCI.\nAs a final result, you will get the pipeline that:\n* runs tests after each commit;\n* builds containers from development and master branches;\n* pushes them into the ECR;\n* redeploys development and production EC2 instances from the development and master containers respectively.\n\nThis guide consists of three parts:\n* ➡️ **Preparation** - where I'll explain this workflow, and show how to prepare an application for it \n* AWS - this chart is about how to set up the AWS environment from scratch;\n* CircleCI - here I'll demonstrate how to automatize deployment process using [circleci.com](circleci.com)\n\n### Workflow\n\nWhen you developing applications in \"real life\" you usually(but not always), sooner or later, found that you need to:\n* 🤖 run automatic tests;\n* 🔍 run different checks(code coverage, security audit, code style, etc.);\n* 🧪 test how a feature works before you deploy it to the production;\n* 💸 deliver results as fast as possible.\n\nThere is an example of a workflow that was used in many projects where I've participated. It works very well in small(3-8 person) teams:\n\n1) Create a branch for a feature from master\n2) Work\n3) Push this feature\n4) **Optionally** Run tests, checks, etc. for this branch \n5) In case of success merge this branch to the development branch\n6) Run everything again and redeploy the development server\n7) Test it manually\n8) Merge feature to the production branch\n9) Redeploy production\n\n\u003cfigure class=\"image\"\u003e\n  \u003cimg src=\"https://habrastorage.org/webt/sb/u5/yl/sbu5ylcp45dfnza5b8__lnoboye.png\"\u003e\n  \u003cfigcaption\u003eWorkflow example\u003c/figcaption\u003e\n\u003c/figure\u003e\n\nI'm going to show how it can work on the workflow with two main branches: \n* master - has tested, production-ready code(deploys on a production server after approving)\n* development - based on the master and also has changes that being tested now(deploys on a development server right after changes on the github)\n\n## Prepare the application\n\nAs an example let's take a simple API server with one route written on the Elixir. I will not explain here how to create it, there is a fantastic [post](https://dev.to/jonlunsford/elixir-building-a-small-json-endpoint-with-plug-cowboy-and-poison-1826) about. Or you can use [my application](https://github.com/evanilukhin/simple_plug_server), it is already configured and prepared. \nThere I'll focus only on the specific moments that are needed to prepare the server for work in this environment. \n\n### Prepare release application\n\nThis Elixir application I am going to deploy using mechanism of [releases](https://hexdocs.pm/mix/Mix.Tasks.Release.html).\nBriefly, it generates an artefact that contains the Erlang VM and its runtime, compiled source code and launch scripts.\n\n---\n\nLet me make a little digress to tell about the methodology I'm trying to follow for designing microservices. \nI'm talking about [12 factor app manifest](https://12factor.net). It's a set of recommendations for building software-as-a-service apps that:\n* Use declarative formats for setup automation, to minimize time and cost for new developers joining the project.    \n* Have a clean contract with the underlying operating system, offering maximum portability between execution environments.    \n* Are suitable for deployment on modern cloud platforms, obviating the need for servers and systems administration.    \n*  Minimize divergence between development and production, enabling continuous deployment for maximum agility.    \n* And can scale up without significant changes to tooling, architecture, or development practices.\n\n---\n\n[One of these principles](https://12factor.net/config) recommends us to store configurable parameters(ports, API keys, services addresses, etc.) in system environment variables. To configure our release application using them you should create the file `config/releases.exs` and describe these variables:\n\n```elixir\nimport Config\n\nconfig :simple_plug_server, port: System.get_env(\"PORT\")\n```\n\nMore about different config files in Elixir applications you can find [here](https://elixir-lang.org/getting-started/mix-otp/config-and-releases.html#configuring-releases) \nand [here](https://hexdocs.pm/mix/Mix.Tasks.Release.html#module-application-configuration)\n\n### Launch script\n\nNext thing I would like to cover is starting an application. The most common way is to use a special shell script\nfor it that contains different preparation steps like waiting for a database, initializing system variables, etc. Also,\nit makes your Docker file more expressive. I think you will agree that `CMD [\"bash\", \"./simple_plug_server/entrypoint.sh\"]` looks better than `CMD [\"bash\", \"cmd1\", \"arg1\", \"arg2\", \";\" \"cmd2\", \"arg1\", \"arg2\", \"arg3\"]`. The entrypoint script for this server is very simple:\n```sh\n#!/bin/sh\n\nbin/simple_plug_server start\n```\n\nThis application works in the docker container so the last command `bin/simple_plug_server start` starts\napp without daemonizing it and writes logs right into the stdout. That allows us to [gather logs](https://12factor.net/logs) simpler(AWS Cloudwatch gathers these data without additional configs).\n\n### Dockerization\n\nAnd on the last step, you should create the [Dockerfile](Dockerfile) that builds result container. I prefer to use two steps builds for Elixir applications because result containers are very thin(approx. 50-70MB).\n```dockerfile\nFROM elixir:1.10.0-alpine as build\n\n# install build dependencies\nRUN apk add --update git build-base\n\n# prepare build dir\nRUN mkdir /app\nWORKDIR /app\n\n# install hex + rebar\nRUN mix local.hex --force \u0026\u0026 \\\n    mix local.rebar --force\n\n# set build ENV\nENV MIX_ENV=prod\n\n# install mix dependencies\nCOPY mix.exs mix.lock ./\nCOPY config config\nRUN mix deps.get\nRUN mix deps.compile\n\n# build project\nCOPY lib lib\nRUN mix compile\n\n# build release\nRUN mix release\n\n# prepare release image\nFROM alpine:3.12 AS app\nRUN apk add --update bash openssl\n\nRUN mkdir /app\nWORKDIR /app\n\nCOPY --from=build /app/_build/prod/rel/simple_plug_server ./\nCOPY --from=build /app/lib/simple_plug_server/entrypoint.sh ./simple_plug_server/entrypoint.sh\nRUN chown -R nobody: /app\nUSER nobody\n\nENV HOME=/app\n\nCMD [\"bash\", \"./simple_plug_server/entrypoint.sh\"]\n```\n\nFinally you can build it using `docker build .`, and  run `docker run -it -p 4000:4000 -e PORT=4000 {IMAGE_ID}`. \nThe server will be available on the `localhost:4000` and will write logs to the stdout. 🎉\n\nOn the next part of this tutorial, I'll show how to automatically build images using CircleCI and push them to the Amazon ECR.\n\n\n",
    "tags": ["aws", "devops", "elixir"]
  },
  {
    "header": "CircleCI + AWS How to create CI/CD pipeline from scratch Part 1 - Build and push images ",
    "head_image": "https://res.cloudinary.com/practicaldev/image/fetch/s--CJXVV2sJ--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://dev-to-uploads.s3.amazonaws.com/i/aiq1bx72jl0xlzi3vwxy.png",
    "summary": "Prepare environment for containers            Create an IAM user   Right after the creation...",
    "main_part": "## Prepare environment for containers\n\n### Create an IAM user\n\nRight after the creation of an AWS account, you are logging in under the root user. You have full access to every service and the billing management console. To secure interaction with AWS it is a good practice to create a new user inside the group that has only required permissions. \n    \nA few words about managing permissions. There are two main ways to add them to users through [groups](https://docs.aws.amazon.com/IAM/latest/UserGuide/id_groups.html) and [roles](https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles.html). The main difference is in that groups are a collection of users with the same policies. Roles, in turn, can be used to delegate access not only to users but also to other services and applications, we will use both. Let's create them.\n\n\u003cfigure class=\"image\"\u003e\n  \u003cimg src=\"https://dev-to-uploads.s3.amazonaws.com/i/u820ir2b0h6d17w0nt3h.png\"\u003e\n  \u003cfigcaption\u003eCreate group window\u003c/figcaption\u003e\n\u003c/figure\u003e\n\nOn the second step select the next policies\n\n* AmazonEC2ContainerRegistryFullAccess \n* AWSCodeDeployRoleForECS \n* AmazonEC2ContainerServiceFullAccess \n* AmazonECSTaskExecutionRolePolicy \n\n\u003cfigure class=\"image\"\u003e\n  \u003cimg src=\"https://dev-to-uploads.s3.amazonaws.com/i/pnsb3cbigw9y6aph2bzd.png\"\u003e\n  \u003cfigcaption\u003eGroup after creation\u003c/figcaption\u003e\n\u003c/figure\u003e\n\nThen create the role that we will give to ECS to deploy our containers to EC2 instances.\n\n\u003cfigure class=\"image\"\u003e\n  \u003cimg src=\"https://dev-to-uploads.s3.amazonaws.com/i/xnhhkaoebhl469ay2rl3.png\"\u003e\n  \u003cfigcaption\u003eCreate role\u003c/figcaption\u003e\n\u003c/figure\u003e\n\nand on the second step select in policies `AmazonEC2ContainerServiceforEC2Role`\n\n\u003cfigure class=\"image\"\u003e\n  \u003cimg src=\"https://dev-to-uploads.s3.amazonaws.com/i/bbh6q9gjcmjwnuyxcyhs.png\"\u003e\n  \u003cfigcaption\u003eResult\u003c/figcaption\u003e\n\u003c/figure\u003e\n\nMore about it is showed [there](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/instance_IAM_role.html)\n\nAnd finally, let's add a new user and add to the previously created group:\n\n\u003cfigure class=\"image\"\u003e\n  \u003cimg src=\"https://dev-to-uploads.s3.amazonaws.com/i/ayi69xqennnmfk0kw6a7.png\"\u003e\n  \u003cfigcaption\u003eNew user\u003c/figcaption\u003e\n\u003c/figure\u003e\n\nThis user should have only programmatic access because you will use it only from the circleci. After it, generate access keys and save them, they will need you later.\n\n### Create ECR\n\n[ECR](https://docs.aws.amazon.com/AmazonECR/latest/userguide/what-is-ecr.html) a place where you will store containers from they will be deployed. Just go to the ECR and click on the \"Create repository\" button. You will see the window where you should select the name for the repository. Other \nsettings use by default\n\n\u003cfigure class=\"image\"\u003e\n  \u003cimg src=\"https://dev-to-uploads.s3.amazonaws.com/i/6kx7227c33esz22b3w28.png\"\u003e\n  \u003cfigcaption\u003eECR Create\u003c/figcaption\u003e\n\u003c/figure\u003e\n\nGreat! You have a repository and all required credentials to build and push images. Time to automatize it.\n\n\u003cfigure class=\"image\"\u003e\n  \u003cimg src=\"https://dev-to-uploads.s3.amazonaws.com/i/yvbzmmqqgfcw4ixfycs0.png\"\u003e\n  \u003cfigcaption\u003eECR After creation\u003c/figcaption\u003e\n\u003c/figure\u003e\n\n## Configuring Circle CI\n\nThe main idea is to run tests after each commit for all branches and deploy after changes in the development and master.\n\nBefore you start to configure the pipeline, you will need to prepare the application\nfollowing this fantastic [getting started](https://circleci.com/docs/2.0/getting-started/#section=getting-started) page.\n\n### Tests\n\nThe most popular use case of the Circle CI that I've seen is running tests (not all developers trust to external\nservices to deploy applications). To run them you should define [a job](https://circleci.com/docs/2.0/jobs-steps/#jobs-overview)\nand add it as a step to [a workflow](https://circleci.com/docs/2.0/workflows/). There is an example of `test` workflow\nfor the `simple_plug_server` application:\n\n```yaml\nversion: 2.1\njobs:\n  test:\n    docker:\n      - image: elixir:1.10\n        environment:\n          MIX_ENV: test\n    working_directory: ~/repo\n    steps:\n      - checkout\n      - run: mix local.hex --force\n      - run: mix local.rebar --force\n      - run: mix deps.get\n      - run: mix deps.compile\n      - run: mix test\n      - store_test_results:\n          path: _build/test/lib/simple_plug_server\nworkflows:\n  version: 2\n  test:\n    jobs:\n      - test\n```\n\nIt has only the one workflow `test` with the one job `test`. This job has three parts: \n* docker - where is defined as a container inside which you will deploy test environment and run tests\n* working_directory - the name of the folder where everything is happening\n* steps - the set of commands where you download code, setup dependencies and finally run tests. \nYou can also [cache dependencies](https://circleci.com/docs/2.0/caching/) on this step.\n\nWe can also improve the representing of the failed tests, for it you should add a JUnit formatter for test results\n(for elixir it is the hex package [JUnitFormatter](https://github.com/victorolinasc/junit-formatter)) and specify\nthe directory containing subdirectories of JUnit XML or Cucumber JSON test metadata files. \nMore information about it and how to add support for other languages and test frameworks look [here](https://circleci.com/docs/2.0/collect-test-data/).\n\n\n### Build and push containers\n\nOn the previous steps we created the ECR repository and the user that can push images, time to setup CircleCI config.\n\nFor work with images we will use the official orb for ECR [circleci/aws-ecr@6.9.1](https://circleci.com/orbs/registry/orb/circleci/aws-ecr)\nIt significantly simplifies building and pushing images, let's add the new step to our config file:\n\n```yaml\nversion: 2.1\norbs:\n  aws-ecr: circleci/aws-ecr@6.9.1\n  aws-ecs: circleci/aws-ecs@1.2.0\njobs:\n  test:\n    docker:\n      - image: elixir:1.10\n        environment:\n          MIX_ENV: test\n    working_directory: ~/repo\n    steps:\n      - checkout\n      - run: mix local.hex --force\n      - run: mix local.rebar --force\n      - run: mix deps.get\n      - run: mix deps.compile\n      - run: mix test\n      - store_test_results:\n          path: _build/test/lib/simple_plug_server\nworkflows:\n  version: 2\n  test-and-build:\n    jobs:\n      - test\n      - aws-ecr/build-and-push-image:\n          repo: \"simple_plug_server\"\n          tag: \"${CIRCLE_BRANCH}_${CIRCLE_SHA1},${CIRCLE_BRANCH}_latest\"\n          requires:\n            - test\n          filters:\n            branches:\n              only:\n                - master\n                - development\n```\n\nBriefly about the steps of this job:\n* repo - the name of the repository (last part of the `815991645042.dkr.ecr.us-west-2.amazonaws.com/simple_plug_server`)\n* tag - tags that we apply to the built container, for the master branch it will add two tags: \nmaster_02dacfb07f7c09107e2d8da9955461f025f7f443 and master_latest\n* requires - there you should describe the previous necessary steps, in this example we build an image only \nif all tests pass\n* filters - describe for which branches this job should execute. There are a lot of other [filters](https://circleci.com/docs/2.0/configuration-reference/#filters-1)\nthat you can use to customize a workflow\n\nBut before you start to run this workflow you should add the next environment variables:\n* AWS_ACCESS_KEY_ID - access key for `circleci` that you obtained on [this step]()\n* AWS_SECRET_ACCESS_KEY - secret key for `circleci` that you obtained on [this step]()\n* AWS_REGION - region where placed your ECR instance\n* AWS_ECR_ACCOUNT_URL - url of the ECR(looks like 815991645042.dkr.ecr.us-west-2.amazonaws.com)\n\n\u003cfigure class=\"image\"\u003e\n  \u003cimg src=\"https://dev-to-uploads.s3.amazonaws.com/i/cyb0myv33xnqv93a2rqv.png\"\u003e\n  \u003cfigcaption\u003eCircleCI ENV Settings example\u003c/figcaption\u003e\n\u003c/figure\u003e\n\nAfter successful build of the development and master branches you will see something like there: \n\n\u003cfigure class=\"image\"\u003e\n  \u003cimg src=\"https://dev-to-uploads.s3.amazonaws.com/i/frjverkv167wd4qcquu2.png\"\u003e\n  \u003cfigcaption\u003eECR after the successful push\u003c/figcaption\u003e\n\u003c/figure\u003e\n\nGreat! You automatized process of running tests and building images in the next chapter you will see how to\nsetup servers on the AWS infrastructure and redeploy them after successfully passed tests.\n\n",
    "tags": ["devops", "aws"]
  },
  {
    "header": "CircleCI + AWS How to create CI/CD pipeline from scratch Part 2 - Setup and update servers ",
    "head_image": "https://res.cloudinary.com/practicaldev/image/fetch/s--mWhQEnJE--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://dev-to-uploads.s3.amazonaws.com/i/mdo8izm0gsx7u5rnpt2q.png",
    "summary": "After all previous steps, you've got the images that are stored inside the ECR and the script that au...",
    "main_part": "After all previous steps, you've got the images that are stored inside the ECR and the script that automatically build\nthem. In this part of the tutorial we will: \n* setup ECS clusters for development and production environments;\n* add deployment commands to the CircleCI script.\n\nLet's do it!\n\n## Initialize ECS cluster\n\nCreating of cluster consists of three steps:\n1. Create an empty cluster with a VPC\n2. Define the task that will launch the selected container\n3. Add service that will launch and maintain the desired count of ec2 instances with the previously defined task\n\n### Create cluster\nLet's start with the definition of [cluster](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/clusters.html): \n\n\u003e An Amazon ECS cluster is a logical grouping of tasks or services. \n\nRoughly saying, clusters define the scope and set of rules for the launched tasks. To create one, follow the steps below:\n\n1. Select EC2 Linux + Networking you need two clusters one for development and one for master branches\n2. Select 1 `On Demand` t2.micro instance(or other types of ec2 instances), other configurations by default\n\n    \u003cfigure class=\"image\"\u003e\n      \u003cimg src=\"https://dev-to-uploads.s3.amazonaws.com/i/k7mqxf1g01ymaoi0t2pf.png\"\u003e\n      \u003cfigcaption\u003eCreate cluster\u003c/figcaption\u003e\n    \u003c/figure\u003e\n\n3. For the networking section, I recommend to use the default parameters too. It will create a new VPC with\n[security group](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-security-groups.html) allowing income traffic\nto the 80 PORT.\n\n\u003cfigure class=\"image\"\u003e\n  \u003cimg src=\"https://dev-to-uploads.s3.amazonaws.com/i/ynh1k3ba8tuyl3xkznkk.png\"\u003e\n  \u003cfigcaption\u003eConfigure network during creation\u003c/figcaption\u003e\n\u003c/figure\u003e\n\nYes, that's all, you should create one for the development and one for the production. \n\n### Define task\n\n[Tasks](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task_definitions.html) are used to run Docker containers in Amazon ECS. \n\n1. Select EC2 launch type compatibility\n2. Choose the name for the task definition(or family, like sometimes it's called)\n3. For the as the task role choose the role with the `AmazonECSTaskExecutionRolePolicy` policy that we  previously created \n4. Select the memory limit, for example, 128 MB if your server is not going to handle a lot of complex requests\n5. And finally, add a container. On this tab we are interested in the following fields:\n   * Standard -\u003e Image - initial image for the task should be copied from the ECR looks like 845992245040.dkr.ecr.us-west-2.amazonaws.com/simple_plug_server:master_latest\n   * Standard -\u003e Port mappings - associate host 80 with the port which is using our application and will be defined next\n       \u003cfigure class=\"image\"\u003e\n  \u003cimg src=\"https://dev-to-uploads.s3.amazonaws.com/i/lnqwg6i59irnpzis8ed2.png\"\u003e\n        \u003cfigcaption\u003eAdd container to a task and configure the port mapping\u003c/figcaption\u003e\n         \u003c/figure\u003e\n\n* Advanced container configuration -\u003e ENVIRONMENT -\u003e Environment variables - define the variable with the name `PORT` and desired value for example - 4100. This value must be used in the port mapping as the container port\n\u003cfigure class=\"image\"\u003e\n  \u003cimg src=\"https://dev-to-uploads.s3.amazonaws.com/i/htqejj8nruz7azy328iv.png\"\u003e\n  \u003cfigcaption\u003eSet up environment variables\u003c/figcaption\u003e\n\u003c/figure\u003e\n   \nGreat! You've created the first revision of the task definition. Of course, these tasks can be launched right inside the cluster, but we will use services to simplify updating tasks revisions. Let's add them. \n\n### Add service\n\n\u003e An Amazon ECS service enables you to run and maintain a specified number of instances of a task definition simultaneously in an Amazon ECS cluster. \n\nTo create a [service](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs_services.html) just click on the `Create` button on the `Services` and fill the form:\n1. Select EC2 in the `Launch type` selector, because we are deploying our tasks on EC2 instances\n2. In the `Task Definition` select the task and revision that you are created earlier\n3. In the `Cluster` select the cluster where you want to define a service. When you are creating service from a cluster this field will be already selected\n4. `Service type` - REPLICA\n5. `Number of tasks` - 1 because we do not care about scaling for now.\n6. Other setting set by default\n\n\u003cfigure class=\"image\"\u003e\n  \u003cimg src=\"https://dev-to-uploads.s3.amazonaws.com/i/yoeullialw88olce81sf.png\"\u003e\n  \u003cfigcaption\u003eService creation\u003c/figcaption\u003e\n\u003c/figure\u003e\n\nAfter repeating all steps for the development and production cluster, you've got two EC2 instances with running applications. They are available by Public DNS or IP.\n\n\u003cfigure class=\"image\"\u003e\n  \u003cimg src=\"https://dev-to-uploads.s3.amazonaws.com/i/6pzerqn1gn7iq6dacnrt.png\"\u003e\n  \u003cfigcaption\u003eService creation\u003c/figcaption\u003e\n\u003c/figure\u003e\n\nNow let's go to the final part of this tutorial. 🚀\n \n## Add deployment scripts\n\nWith an official orb [aws-ecs](https://circleci.com/orbs/registry/orb/circleci/aws-ecs) you can make this very easy. We already added all necessary environment variables in the second part of this tutorial so you should only modify the circleci config. \n\nResult version of the `.circleci/config.yml`\n```yaml\nversion: 2.1\norbs:\n  aws-ecr: circleci/aws-ecr@6.9.1\n  aws-ecs: circleci/aws-ecs@1.2.0\njobs:\n  test:\n    docker:\n      - image: elixir:1.10\n        environment:\n          MIX_ENV: test\n    working_directory: ~/repo\n    steps:\n      - checkout\n      - run: mix local.hex --force\n      - run: mix local.rebar --force\n      - run: mix deps.get\n      - run: mix deps.compile\n      - run: mix test\n      - store_test_results:\n          path: _build/test/lib/simple_plug_server\nworkflows:\n  version: 2\n  test-build-deploy:\n    jobs:\n      - test\n      - aws-ecr/build-and-push-image:\n          repo: \"simple_plug_server\"\n          tag: \"${CIRCLE_BRANCH}_${CIRCLE_SHA1},${CIRCLE_BRANCH}_latest\"\n          requires:\n            - test\n          filters:\n            branches:\n              only:\n                - master\n                - development\n      - aws-ecs/deploy-service-update:\n          name: deploy-development\n          requires:\n            - aws-ecr/build-and-push-image \n          family: \"simple-plug-server-development\"\n          cluster-name: \"SimplePlugServer-development\"\n          service-name: \"sps-dev-serv\"\n          container-image-name-updates: \"container=simple-plug-server-development,tag=${CIRCLE_BRANCH}_${CIRCLE_SHA1}\"\n          filters:\n            branches:\n              only:\n                - development\n      - approve-deploy:\n          type: approval\n          requires:\n            - aws-ecr/build-and-push-image\n          filters:\n            branches:\n              only:\n                - master\n      - aws-ecs/deploy-service-update:\n          name: deploy-production\n          requires:\n            - approve-deploy\n          family: \"simple-plug-server-production\"\n          cluster-name: \"SimplePlugServer-production\"\n          service-name: \"simple-plug-server-production\"\n          container-image-name-updates: \"container=simple-plug-server-production,tag=${CIRCLE_BRANCH}_${CIRCLE_SHA1}\"\n          filters:\n            branches:\n              only:\n                - master\n```\n\nIn this file was added three new jobs. Two `aws-ecs/deploy-service-update` respond for the updating respective services in the clusters and `approve-deploy` that's waiting for confirmation before the last step for the master branch. For different branches, flows will be a little different. It can be achieved by using parameter `filters` in job definitions, where you can specify for which branches or git tags launch jobs.\n\n### aws-ecs/deploy-service-update job configuration\n\nI would like to tell you about the parameters for the job `aws-ecs/deploy-service-update`:\n* **name** - the name is used to make jobs in a workflow more human-readable. I am sure you would agree that's `deploy-production`\nlooks much more clearer than `aws-ecs/deploy-service-update`. \n* **requires** - used to define the order of jobs execution, namely the previous job that must be finished successfully.\n* **family** - there you should write the name of the task definition([Define task](define-task)) that you used when you \ncreated the task\n* **cluster-name** - it's pretty obvious - the name of the desired cluster where all magic happens\n* **service-name** - the name of the service that's managing tasks inside the previously mentioned cluster\n* **container-image-name-updates** - updates the Docker image names and/or tag names of existing containers \n                                 that had been defined in the previous task definition\n  * **container** - the name of the container that you used when you added the container to the task(circled in blue on the screenshot `Add container to a task and configure the port mapping`)\n  * **tag** - one of the tags that you are defined in the `aws-ecr/build-and-push-image` job, in this example it's a `${CIRCLE_BRANCH}_${CIRCLE_SHA1}`\n\nAnd that's all 🎉. When you push your branch with the new circleci config and start to work you will see something like that.\n\n\u003cfigure class=\"image\"\u003e\n  \u003cimg src=\"https://dev-to-uploads.s3.amazonaws.com/i/f7efsjc1ws5slo40k0mx.png\"\u003e\n  \u003cfigcaption\u003eService creation\u003c/figcaption\u003e\n\u003c/figure\u003e\n\nI hope that this tutorial was helpful and was not wasted your time. If you have any question and problems feel free to ask me about it in the comments. 👋\n",
    "tags": ["aws", "devops"]
  }
]


